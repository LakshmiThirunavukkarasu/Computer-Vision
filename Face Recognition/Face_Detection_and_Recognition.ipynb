{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LakshmiThirunavukkarasu/Computer-Vision/blob/main/Face_Detection_and_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k2tmF7DCn5O",
    "outputId": "ca6c09a8-dfdb-4e10-ade6-89d0183f9e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facenet_pytorch\n",
      "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▏                               | 10 kB 23.8 MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 20 kB 28.8 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 30 kB 33.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 40 kB 34.5 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 51 kB 24.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 61 kB 26.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 71 kB 27.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 81 kB 28.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 92 kB 30.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 102 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 112 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 122 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 133 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 143 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 153 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 163 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 174 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 184 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 194 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 204 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 215 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 225 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 235 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 245 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 256 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 266 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 276 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 286 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 296 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 307 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 317 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 327 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 337 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 348 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 358 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 368 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 378 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 389 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 399 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 409 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 419 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 430 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 440 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 450 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 460 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 471 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 481 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 491 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 501 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 512 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 522 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 532 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 542 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 552 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 563 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 573 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 583 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 593 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 604 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 614 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 624 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 634 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 645 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 655 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 665 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 675 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 686 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 696 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 706 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 716 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 727 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 737 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 747 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 757 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 768 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 778 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 788 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 798 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 808 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 819 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 829 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 839 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 849 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 860 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 870 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 880 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 890 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 901 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 911 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 921 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 931 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 942 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 952 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 962 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 972 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 983 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 993 kB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.0 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 1.0 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.0 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 1.0 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 1.0 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 1.1 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.2 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 1.3 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 1.4 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.5 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.6 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.7 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.8 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 1.9 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.9 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.9 MB 31.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.9 MB 31.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.12.0+cu113)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.21.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (4.2.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.11.0+cu113)\n",
      "Installing collected packages: facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l40LaUVBMhLG"
   },
   "source": [
    "**Load the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5McpzxySZZAl"
   },
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training, extract_face\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, SequentialSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wP6ej3-YGYQq"
   },
   "source": [
    "**Collect Faces from lfw dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C9uwB78GM3-o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "DATA_DIR = os.path.join(\"/content\", \"FaceRec-Dataset\")\n",
    "TEST_DATA_DIR = os.path.join(os.path.join(\"/content\", \"FaceRec-Dataset\"),'Test')\n",
    "TRAIN_DATA_DIR = os.path.join(os.path.join(\"/content\", \"FaceRec-Dataset\"),'Train')\n",
    "\n",
    "if os.path.exists(TRAIN_DATA_DIR) and os.path.isdir(TRAIN_DATA_DIR):\n",
    "  shutil.rmtree(TRAIN_DATA_DIR)\n",
    "\n",
    "if os.path.exists(TRAIN_DATA_DIR + \"_cropped\") and os.path.isdir(TRAIN_DATA_DIR + \"_cropped\"):\n",
    "  shutil.rmtree(TRAIN_DATA_DIR + \"_cropped\")\n",
    "\n",
    "if os.path.exists(TEST_DATA_DIR) and os.path.isdir(TEST_DATA_DIR):\n",
    "  shutil.rmtree(TEST_DATA_DIR)\n",
    "\n",
    "if os.path.exists(DATA_DIR) and os.path.isdir(DATA_DIR):\n",
    "  shutil.rmtree(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lWZjQG1UPaRc"
   },
   "outputs": [],
   "source": [
    "!mkdir \"/content/FaceRec-Dataset\"\n",
    "!mkdir \"/content/FaceRec-Dataset/Train\"\n",
    "!mkdir \"/content/FaceRec-Dataset/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUlSFLTDvGt6",
    "outputId": "d45931ae-b81d-4ad9-8b4d-8fac9930f2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "total_count = len(lfw_people.images)\n",
    "print(total_count)\n",
    "\n",
    "classes = {}\n",
    "for i in range(len(lfw_people.target_names)):\n",
    "  classes[i] = lfw_people.target_names[i]\n",
    "\n",
    "train_idx  = 0\n",
    "test_idx = 0\n",
    "img_idx = 0\n",
    "\n",
    "for i in range(len(lfw_people.images)):\n",
    "  #print(\"iteration \", i)\n",
    "\n",
    "  img = Image.fromarray(lfw_people.images[i])\n",
    "  img = img.convert(\"RGB\")\n",
    "  \n",
    "  if test_idx == 1:\n",
    "    path = os.path.join(TEST_DATA_DIR, classes[lfw_people.target[i]])\n",
    "    test_idx = test_idx + 1\n",
    "  else:\n",
    "    path = os.path.join(TRAIN_DATA_DIR, classes[lfw_people.target[i]])\n",
    "  \n",
    "\n",
    "  if  not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "  #print(os.path.join(path, \"img\" + str(img_idx) + \".jpg\"))\n",
    "  img.save(os.path.join(path, \"img\" + str(img_idx) + \".jpg\"))\n",
    "  img_idx = img_idx + 1\n",
    "  \n",
    "  if train_idx == 500:\n",
    "    test_idx = 1\n",
    "  else:\n",
    "    train_idx = train_idx + 1\n",
    "\n",
    "  if test_idx == 100:\n",
    "    break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ArMgcSCG3Sx"
   },
   "source": [
    "**Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3CGKiWzzZb82"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 15\n",
    "workers = 0 if os.name == 'nt' else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXFCYY56Z275",
    "outputId": "326c4baf-8611-4e14-c704-ca0a9a04fe8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9VHtbNHHGcE"
   },
   "source": [
    "**Face Detection using MTCNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wAoSC2PCZ59u"
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160,\n",
    "    margin=14,\n",
    "    device=device,\n",
    "    selection_method='center_weighted_size'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VpQip-sdZ9Ro"
   },
   "outputs": [],
   "source": [
    "# Define the data loader for the input set of images\n",
    "orig_img_ds = datasets.ImageFolder(TRAIN_DATA_DIR, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Eddlj-WaJF5",
    "outputId": "536a51f8-bb0b-4b84-a4ad-796331497e24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# overwrites class labels in dataset with path so path can be used for saving output in mtcnn batches\n",
    "orig_img_ds.samples = [\n",
    "    (p, p)\n",
    "    for p, _ in orig_img_ds.samples\n",
    "]\n",
    "\n",
    "loader = DataLoader(\n",
    "    orig_img_ds,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tasHintNaMdQ",
    "outputId": "11d79fb2-25d4-4c21-aff2-80667409e4af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
      "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/utils/detect_face.py:183: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  batch_boxes, batch_points = np.array(batch_boxes), np.array(batch_points)\n",
      "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:339: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  boxes = np.array(boxes)\n",
      "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:341: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  points = np.array(points)\n",
      "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:444: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  selected_boxes = np.array(selected_boxes)\n",
      "/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py:446: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  selected_points = np.array(selected_points)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32 of 32"
     ]
    }
   ],
   "source": [
    "crop_paths = []\n",
    "box_probs = []\n",
    "\n",
    "for i, (x, b_paths) in enumerate(loader):\n",
    "    crops = [p.replace(TRAIN_DATA_DIR, TRAIN_DATA_DIR + '_cropped') for p in b_paths]\n",
    "    mtcnn(x, save_path=crops)\n",
    "    crop_paths.extend(crops)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BJEHO7uvab4f"
   },
   "outputs": [],
   "source": [
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzh3q99QHpPT"
   },
   "source": [
    "**Face Alignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tj-WginraftT",
    "outputId": "595be7a5-91d4-4606-9ec2-6133bdf0dad7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# create dataset and data loaders from cropped images output from MTCNN\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(TRAIN_DATA_DIR + '_cropped', transform=trans)\n",
    "\n",
    "embed_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SequentialSampler(dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EGvXk13IPKj"
   },
   "source": [
    "**Feature Extraction: Extract Face embeddings using pretrained Resnet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tohDJGOZaydd"
   },
   "outputs": [],
   "source": [
    "# Load pretrained resnet model\n",
    "resnet = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained='vggface2'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgsrHySlIqCg"
   },
   "source": [
    "**Dictionary of Face Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2WsiWsqa1of",
    "outputId": "44e20765-8a6d-4fdf-cc9b-4253671eed89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "embeddings = []\n",
    "resnet.eval()\n",
    "with torch.no_grad():\n",
    "    for xb, yb in embed_loader:\n",
    "        xb = xb.to(device)\n",
    "        b_embeddings = resnet(xb)\n",
    "        b_embeddings = b_embeddings.to('cpu').numpy()\n",
    "        classes.extend(yb.numpy())\n",
    "        embeddings.extend(b_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "l6j_af2Ua6wU"
   },
   "outputs": [],
   "source": [
    "embeddings_dict = dict(zip(crop_paths,embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfINQUgXI_vW"
   },
   "source": [
    "**Feature Matching based on Cosine similarity of the embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "X35dbMnva-nL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "\n",
    "# LFW functions taken from David Sandberg's FaceNet implementation\n",
    "def distance(embeddings1, embeddings2, distance_metric=0):\n",
    "    if distance_metric==0:\n",
    "        # Euclidian distance\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff),1)\n",
    "    elif distance_metric==1:\n",
    "        # Distance based on cosine similarity\n",
    "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n",
    "        norm = np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n",
    "        similarity = dot / norm\n",
    "        dist = np.arccos(similarity) / math.pi\n",
    "    else:\n",
    "        raise 'Undefined distance metric %d' % distance_metric\n",
    "\n",
    "    return dist\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=2, distance_metric=0, subtract_mean=False):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "\n",
    "    is_false_positive = []\n",
    "    is_false_negative = []\n",
    "\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        if subtract_mean:\n",
    "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
    "        else:\n",
    "          mean = 0.0\n",
    "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
    "\n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx], _ ,_ = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _, _, _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "        _, _, accuracy[fold_idx], is_fp, is_fn = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "\n",
    "        tpr = np.mean(tprs,0)\n",
    "        fpr = np.mean(fprs,0)\n",
    "        is_false_positive.extend(is_fp)\n",
    "        is_false_negative.extend(is_fn)\n",
    "\n",
    "    return tpr, fpr, accuracy, is_false_positive, is_false_negative\n",
    "\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "\n",
    "    is_fp = np.logical_and(predict_issame, np.logical_not(actual_issame))\n",
    "    is_fn = np.logical_and(np.logical_not(predict_issame), actual_issame)\n",
    "\n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
    "    acc = float(tp+tn)/dist.size\n",
    "    return tpr, fpr, acc, is_fp, is_fn\n",
    "\n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=2, distance_metric=0, subtract_mean=False):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        if subtract_mean:\n",
    "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
    "        else:\n",
    "          mean = 0.0\n",
    "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
    "\n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
    "        if np.max(far_train)>=far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "\n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
    "\n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "\n",
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    if n_same == 0:  n_same = 0.001\n",
    "    if n_diff == 0:  n_diff = 0.001\n",
    "    #if true_accept == 0:  true_accept = 0.001\n",
    "    #if false_accept == 0:  false_accept = 0.001\n",
    "\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "\n",
    "    return val, far\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(embeddings, actual_issame, nrof_folds=3, distance_metric=0, subtract_mean=False):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    #print(embeddings1)\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    #print(embeddings2)\n",
    "    tpr, fpr, accuracy, fp, fn  = calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\n",
    "    thresholds = np.arange(0, 4, 0.001)\n",
    "    val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\n",
    "    return tpr, fpr, accuracy, val, val_std, far, fp, fn\n",
    "\n",
    "def add_extension(path):\n",
    "    if os.path.exists(path+'.jpg'):\n",
    "        return path+'.jpg'\n",
    "    elif os.path.exists(path+'.png'):\n",
    "        return path+'.png'\n",
    "    else:\n",
    "        raise RuntimeError('No file \"%s\" with extension png or jpg.' % path)\n",
    "\n",
    "def get_paths(lfw_dir, pairs):\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = add_extension(os.path.join(lfw_dir, pair[0], 'img' + '%03d' % int(pair[1])))\n",
    "            path1 = add_extension(os.path.join(lfw_dir, pair[0], 'img' + '%03d' % int(pair[2])))\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = add_extension(os.path.join(lfw_dir, pair[0], 'img' + '%03d' % int(pair[1])))\n",
    "            path1 = add_extension(os.path.join(lfw_dir, pair[2], 'img' + '%03d' % int(pair[3])))\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0,path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs>0:\n",
    "        print('Skipped %d image pairs' % nrof_skipped_pairs)\n",
    "\n",
    "\n",
    "    return path_list, issame_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTHolDYFJRr_"
   },
   "source": [
    "**Create Face Pair for Matching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MerYZ-GkcWdf",
    "outputId": "c93bd8ba-0218-4726-f294-eae4399deb41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "pairs.append(['Ariel Sharon', '111', '137'])\n",
    "pairs.append(['Colin Powell', '115', '224'])\n",
    "pairs.append(['Donald Rumsfeld', '159', '267'])\n",
    "pairs.append(['George W Bush', '100', '123'])\n",
    "pairs.append(['Ariel Sharon', '111', 'Colin Powell', '186'])\n",
    "pairs.append(['Ariel Sharon', '195', 'George W Bush', '109'])\n",
    "pairs.append(['Donald Rumsfeld', '165', 'George W Bush', '109'])\n",
    "\n",
    "\n",
    "path_list, issame_list = get_paths(TRAIN_DATA_DIR+'_cropped', pairs)\n",
    "embeddings = np.array([embeddings_dict[path] for path in path_list])\n",
    "print(issame_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Qsue-0D_ajEk"
   },
   "outputs": [],
   "source": [
    "tpr, fpr, accuracy, val, val_std, far, fp, fn = evaluate(embeddings, issame_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0u8HN5RKHRK"
   },
   "source": [
    "**Performance Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDQXdqIqBgPV",
    "outputId": "a434db0f-7834-48ab-ea70-ac3dcec74cfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.5205555555555555\n",
      "False Positive Rate: 0.4283333333333333\n",
      "Accurancy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate:\", np.mean(tpr))\n",
    "print(\"False Positive Rate:\", np.mean(fpr))\n",
    "print(\"Accurancy:\", np.mean(accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNS2Imhp1ljCyPrhOBoRbkw",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Face Detection and Recognition",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
